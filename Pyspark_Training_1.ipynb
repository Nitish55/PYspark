{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* creating Dummy dataset\n",
    "* pyspark to pandas\n",
    "* Show()\n",
    "* Row\n",
    "* PySpark Column Class----> \n",
    "* alias() for creating alias\n",
    "* expr for combining columns\n",
    "* asc() and dsc()\n",
    "* cast and astype\n",
    "* between()\n",
    "* Contains\n",
    "* endswith() startswith()\n",
    "* Substr()\n",
    "* When()\n",
    "* f.length\n",
    "* Select()\n",
    "* Collect()\n",
    "* withcolum\n",
    "* withcolumnrenamed\n",
    "* Distinct()\n",
    "* dropduplicates()\n",
    "* orderby() sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "from pyspark.sql.functions import col,lit,udf,expr,when\n",
    "spark=SparkSession.builder.appName(\"Training\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* frst meathod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Second Meathod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(data).toDF(*columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"test1.csv\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Age city\n",
      "Nitish 32 delhi\n",
      "rakesh 33 goa\n",
      "king 35 agra\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.text(\"tst.txt\")\n",
    "vl=df.collect()\n",
    "for i in vl:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert pyspark to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|first_name|middle_name|last_name|dob  |gender|salary|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|James     |           |Smith    |36636|M     |60000 |\n",
      "|Michael   |Rose       |         |40288|M     |70000 |\n",
      "|Robert    |           |Williams |42114|      |400000|\n",
      "|Maria     |Anne       |Jones    |39192|F     |500000|\n",
      "|Jen       |Mary       |Brown    |     |F     |0     |\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
    "\n",
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
    "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
    "pysparkDF.printSchema()\n",
    "pysparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn=pysparkDF.toPandas()\n",
    "type(pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show\n",
    "* PySpark show() – Display DataFrame Contents in Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-----+------+------+\n",
      "|first_name|middle_name|last_name|  dob|gender|salary|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|     James|           |    Smith|36636|     M| 60000|\n",
      "|   Michael|       Rose|         |40288|     M| 70000|\n",
      "|    Robert|           | Williams|42114|      |400000|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pysparkDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### truncate\n",
    "* it truncate the fileds even the numric one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+------+\n",
      "|first_name|middle_name|last_name|dob|gender|salary|\n",
      "+----------+-----------+---------+---+------+------+\n",
      "|       Jam|           |      Smi|366|     M|   600|\n",
      "|       Mic|        Ros|         |402|     M|   700|\n",
      "+----------+-----------+---------+---+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pysparkDF.show(2,truncate=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Contents Vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------\n",
      " first_name  | Jam \n",
      " middle_name |     \n",
      " last_name   | Smi \n",
      " dob         | 366 \n",
      " gender      | M   \n",
      " salary      | 600 \n",
      "-RECORD 1----------\n",
      " first_name  | Mic \n",
      " middle_name | Ros \n",
      " last_name   |     \n",
      " dob         | 402 \n",
      " gender      | M   \n",
      " salary      | 700 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pysparkDF.show(2,truncate=3,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nitish Bhardwaj\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "s=Row(\"Nitish\",\"Bhardwaj\")\n",
    "print(s[0]+\" \"+s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\n"
     ]
    }
   ],
   "source": [
    "s=Row(name=\"Alice\", age=11)\n",
    "print(s[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Row class on PySpark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='James,,Smith', lang=['Java', 'Scala', 'C++'], state='CA'), Row(name='Michael,Rose,', lang=['Spark', 'Java', 'C++'], state='NJ'), Row(name='Robert,,Williams', lang=['CSharp', 'VB'], state='NV')]\n"
     ]
    }
   ],
   "source": [
    "data = [Row(name=\"James,,Smith\",lang=[\"Java\",\"Scala\",\"C++\"],state=\"CA\"), \n",
    "    Row(name=\"Michael,Rose,\",lang=[\"Spark\",\"Java\",\"C++\"],state=\"NJ\"),\n",
    "    Row(name=\"Robert,,Williams\",lang=[\"CSharp\",\"VB\"],state=\"NV\")]\n",
    "rdd=spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James,,Smith ['Java', 'Scala', 'C++']\n",
      "Michael,Rose, ['Spark', 'Java', 'C++']\n",
      "Robert,,Williams ['CSharp', 'VB']\n"
     ]
    }
   ],
   "source": [
    "colData=rdd.collect()\n",
    "for i in colData:\n",
    "    print(i.name+\" \"+str(i.lang))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+\n",
      "|            name|              lang|state|\n",
      "+----------------+------------------+-----+\n",
      "|    James,,Smith|[Java, Scala, C++]|   CA|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|   NJ|\n",
      "|Robert,,Williams|      [CSharp, VB]|   NV|\n",
      "+----------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame(data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can also change the columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------+\n",
      "|            name| languagesAtSchool|currentState|\n",
      "+----------------+------------------+------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|          CA|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|          NJ|\n",
      "|Robert,,Williams|      [CSharp, VB]|          NV|\n",
      "+----------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
    "df=spark.createDataFrame(data).toDF(*columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Column Class | Operators & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  null|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')] \n",
    "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 alias() – Set’s name to Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combining fname and lname into name using expr and alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+--------------+\n",
      "|     fname|lname| id|gender|          Name|\n",
      "+----------+-----+---+------+--------------+\n",
      "|     James| Bond|100|  null|    James_Bond|\n",
      "|       Ann|Varsa|200|     F|     Ann_Varsa|\n",
      "|Tom Cruise|  XXX|400|      |Tom Cruise_XXX|\n",
      "| Tom Brand| null|400|     M|          null|\n",
      "+----------+-----+---+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"*\"),expr(\"fname || '_'|| lname\").alias(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Sex|\n",
      "+----+\n",
      "|null|\n",
      "|   F|\n",
      "|    |\n",
      "|   M|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## chnage gender to Sex\n",
    "df.select(df.gender.alias(\"Sex\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- asc() & desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| null|400|     M|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  null|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"id\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  null|\n",
      "| Tom Brand| null|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"fname\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast and astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"test1.csv\",header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age\",col(\"age\").cast(\"int\"))\\\n",
    "  .withColumn(\"Salary\",col(\"Salary\").astype(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Between\n",
    "* between() – Returns a Boolean expression when a column values in between lower and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age.between(21,30)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df[\"age\"].between(21,30)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contains\n",
    "* contains() – Checks if a DataFrame column value contains a a value specified in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.Name.contains(\"S\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## startswith() & endswith() – \n",
    "* Checks if the value of the DataFrame Column starts and ends with a String respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Name.startswith(\"Su\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Name.endswith(\"am\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.Name.startswith(\"Su\")) & (df.Name.endswith(\"u\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isNull & isNotNull() – \n",
    "* Checks if the DataFrame column has NULL or non NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"test1.csv\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|Mahesh|null|      null| 40000|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Name.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### like() & rlike() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|Paul| 24|         3| 20000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.Name.like(\"%au%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|Paul| 24|         3| 20000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.Name.like(\"_a__\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substr() – \n",
    "* Returns a Column after getting sub string from the Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Substr_name|\n",
      "+-----------+\n",
      "|        Kri|\n",
      "|        Sud|\n",
      "|        Sun|\n",
      "|        Pau|\n",
      "|        Har|\n",
      "|        Shu|\n",
      "|        Mah|\n",
      "|       null|\n",
      "|       null|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Name.substr(1,3).alias(\"Substr_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Sunny| 29|         4| 20000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Name.substr(1,3)==\"Sun\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length finding of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-------+\n",
      "|     Name| age|Experience|Salary|new_lth|\n",
      "+---------+----+----------+------+-------+\n",
      "|    Krish|  31|        10| 30000|      5|\n",
      "|Sudhanshu|  30|         8| 25000|      9|\n",
      "|    Sunny|  29|         4| 20000|      5|\n",
      "|     Paul|  24|         3| 20000|      4|\n",
      "|   Harsha|  21|         1| 15000|      6|\n",
      "|  Shubham|  23|         2| 18000|      7|\n",
      "|   Mahesh|null|      null| 40000|      6|\n",
      "|     null|  34|        10| 38000|   null|\n",
      "|     null|  36|      null|  null|   null|\n",
      "+---------+----+----------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df.withColumn(\"new_lth\",f.length(col(\"Name\").alias(\"Name_lth\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## when() & otherwise() –\n",
    "* It is similar to SQL Case When, executes sequence of expressions until it matches the condition and returns a value when match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+------------+\n",
      "|     Name| age|Experience|Salary|       Level|\n",
      "+---------+----+----------+------+------------+\n",
      "|    Krish|  31|        10| 30000|      Expert|\n",
      "|Sudhanshu|  30|         8| 25000|Intermediate|\n",
      "|    Sunny|  29|         4| 20000|Intermediate|\n",
      "|     Paul|  24|         3| 20000|     Fresher|\n",
      "|   Harsha|  21|         1| 15000|     Fresher|\n",
      "|  Shubham|  23|         2| 18000|     Fresher|\n",
      "|   Mahesh|null|      null| 40000|      Expert|\n",
      "|     null|  34|        10| 38000|      Expert|\n",
      "|     null|  36|      null|  null|      Expert|\n",
      "+---------+----+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"*\"),when(col(\"Experience\").between(1,3),\"Fresher\")\\\n",
    "         .when(col(\"Experience\").between(4,8),\"Intermediate\")\\\n",
    "         .otherwise(\"Expert\").alias(\"Level\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l=[3,4,8]\n",
    "df.filter(col(\"Experience\").isin(l)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|        |\n",
      "|   Robert|Williams|\n",
      "|    Maria|   Jones|\n",
      "|      Jen|   Brown|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"firstname\",\"lastname\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fteching all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetching selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|    Krish|        10|\n",
      "|Sudhanshu|         8|\n",
      "|    Sunny|         4|\n",
      "|     Paul|         3|\n",
      "|   Harsha|         1|\n",
      "|  Shubham|         2|\n",
      "|   Mahesh|      null|\n",
      "|     null|        10|\n",
      "|     null|      null|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols=[i for i in df.columns if i not in [\"age\",\"Salary\"]]\n",
    "df2=df.select(cols)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns by Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fetching selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|     Name| age|\n",
      "+---------+----+\n",
      "|    Krish|  31|\n",
      "|Sudhanshu|  30|\n",
      "|    Sunny|  29|\n",
      "|     Paul|  24|\n",
      "|   Harsha|  21|\n",
      "|  Shubham|  23|\n",
      "|   Mahesh|null|\n",
      "|     null|  34|\n",
      "|     null|  36|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[:2]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|age|Experience|\n",
      "+---+----------+\n",
      "| 31|        10|\n",
      "| 30|         8|\n",
      "| 29|         4|\n",
      "+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## fetching age and Experience column\n",
    "df.select(df.columns[1:3]).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  collect() \n",
    "* it is an action operation that is used to retrieve all the elements of the dataset (from all nodes) to the driver node. We should use the collect() on smaller dataset usually after filter(), group() e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', age='31', Experience='10', Salary='30000'),\n",
       " Row(Name='Sudhanshu', age='30', Experience='8', Salary='25000'),\n",
       " Row(Name='Sunny', age='29', Experience='4', Salary='20000'),\n",
       " Row(Name='Paul', age='24', Experience='3', Salary='20000'),\n",
       " Row(Name='Harsha', age='21', Experience='1', Salary='15000'),\n",
       " Row(Name='Shubham', age='23', Experience='2', Salary='18000'),\n",
       " Row(Name='Mahesh', age=None, Experience=None, Salary='40000'),\n",
       " Row(Name=None, age='34', Experience='10', Salary='38000'),\n",
       " Row(Name=None, age='36', Experience=None, Salary=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clct=df.collect()\n",
    "dt=clct\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krish\n",
      "Sudhanshu\n",
      "Sunny\n",
      "Paul\n",
      "Harsha\n",
      "Shubham\n",
      "Mahesh\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in dt:\n",
    "    print(i.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', age='31', Experience='10', Salary='30000'),\n",
       " Row(Name='Sudhanshu', age='30', Experience='8', Salary='25000'),\n",
       " Row(Name='Sunny', age='29', Experience='4', Salary='20000')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Krish'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## withcolumns()\n",
    "* PySpark withColumn() is a transformation function of DataFrame which is used to change the value, convert the datatype of an existing column, create a new column, and many more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change DataType using PySpark withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age\",col(\"age\").cast(\"int\")) \\\n",
    "  .withColumn(\"Salary\",col(\"Salary\").astype(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update The Value of an Existing Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|41.0|        10| 30000|\n",
      "|Sudhanshu|40.0|         8| 25000|\n",
      "|    Sunny|39.0|         4| 20000|\n",
      "|     Paul|34.0|         3| 20000|\n",
      "|   Harsha|31.0|         1| 15000|\n",
      "|  Shubham|33.0|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|44.0|        10| 38000|\n",
      "|     null|46.0|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age\",col(\"age\")+10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating new column\n",
    "\n",
    "* lit() used to create static value in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+------+-------------+\n",
      "|     Name| age|Experience|Salary| Bonus|         City|\n",
      "+---------+----+----------+------+------+-------------+\n",
      "|    Krish|  31|        10| 30000|3000.0|Muzaffarnagar|\n",
      "|Sudhanshu|  30|         8| 25000|2500.0|Muzaffarnagar|\n",
      "|    Sunny|  29|         4| 20000|2000.0|Muzaffarnagar|\n",
      "|     Paul|  24|         3| 20000|2000.0|Muzaffarnagar|\n",
      "|   Harsha|  21|         1| 15000|1500.0|Muzaffarnagar|\n",
      "|  Shubham|  23|         2| 18000|1800.0|Muzaffarnagar|\n",
      "|   Mahesh|null|      null| 40000|4000.0|Muzaffarnagar|\n",
      "|     null|  34|        10| 38000|3800.0|Muzaffarnagar|\n",
      "|     null|  36|      null|  null|  null|Muzaffarnagar|\n",
      "+---------+----+----------+------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Bonus\",(col(\"Salary\")*10)/100) \\\n",
    "  .withColumn(\"City\",lit(\"Muzaffarnagar\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name|Umar|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"age\",\"Umar\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on multiple column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Naam|Umar|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"age\",\"Umar\") \\\n",
    "  .withColumnRenamed(\"Name\",\"Naam\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Distinct to Drop Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]\n",
    "\n",
    "# Create DataFrame\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|      Michael|     Sales|  4600|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"*\")).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|        James|\n",
      "|      Michael|\n",
      "|        Maria|\n",
      "|       Robert|\n",
      "|        Scott|\n",
      "|          Jen|\n",
      "|        Kumar|\n",
      "|         Saif|\n",
      "|         Jeff|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"employee_name\")).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(col(\"department\")).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|      Michael|     Sales|  4600|\n",
      "|        James|     Sales|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping duplicates from multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|      Michael|     Sales|  4600|\n",
      "|        James|     Sales|  3000|\n",
      "|        Maria|   Finance|  3000|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|         Saif|     Sales|  4100|\n",
      "|        Kumar| Marketing|  2000|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates([\"employee_name\",\"department\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct value of employee_name,department : 9\n"
     ]
    }
   ],
   "source": [
    "print(\"distinct value of employee_name,department : \"+str(df.dropDuplicates([\"employee_name\",\"department\"]).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orderby()    sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000), \\\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000), \\\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000), \\\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000), \\\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000), \\\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000) \\\n",
    "  ]\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sorting by mulptiple column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort([\"employee_name\",\"age\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sortuing one column ascending and other descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col(\"department\").asc(),col(\"age\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SPARK_HOME]",
   "language": "python",
   "name": "conda-env-SPARK_HOME-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
