{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GroupBY()\n",
    "* Pivot\n",
    "* Window functions\n",
    "* Sampling\n",
    "* Greatest,Least,First,Last\n",
    "* Collect_list\n",
    "* String Functions- split,length,lower,upper,initcap,trim,padding(lpad,rpad),reverse,repeat,concat,concat_ws,substring,substring_index,instr,locate,translate,overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql.functions import udf,col,length,expr,lit,lower,sumDistinct,sum,round,count,countDistinct,max,min,avg\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"Train_hard\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|Empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 26|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Kylie|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Sales\",\"NY\",9000,34),\n",
    "     (\"Alicia\",\"Sales\",\"NY\",8600,56),\n",
    "     (\"Robert\",\"Sales\",\"CA\",8100,30),\n",
    "     (\"Lisa\",\"Finance\",\"CA\",9000,24),\n",
    "     (\"Deja\",\"Finance\",\"CA\",9900,40),\n",
    "     (\"Sugie\",\"Finance\",\"NY\",8300,26),\n",
    "     (\"Ram\",\"Finance\",\"NY\",7900,53),\n",
    "     (\"Kylie\",\"Marketing\",\"CA\",8000,25),\n",
    "     (\"Reid\",\"Marketing\",\"NY\",9100,50)]\n",
    "schema=(\"Empname\",\"dept\",\"state\",\"salary\",\"age\")\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|     dept|avg(age)|\n",
      "+---------+--------+\n",
      "|    Sales|    40.0|\n",
      "|  Finance|   35.75|\n",
      "|Marketing|    37.5|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"dept\").avg(\"age\").alias(\"Avg_age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|     dept|avg(age)|\n",
      "+---------+--------+\n",
      "|    Sales|    40.0|\n",
      "|  Finance|   35.75|\n",
      "|Marketing|    37.5|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nd=df.groupBy(\"dept\").avg(\"age\").alias(\"Avg_age\")\n",
    "nd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| dept|avg(age)|\n",
      "+-----+--------+\n",
      "|Sales|    40.0|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nd.where(col(\"avg(age)\")>38).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+--------+\n",
      "|     dept|state|min(salary)|min(age)|\n",
      "+---------+-----+-----------+--------+\n",
      "|    Sales|   NY|       8600|      34|\n",
      "|    Sales|   CA|       8100|      30|\n",
      "|  Finance|   CA|       9000|      24|\n",
      "|  Finance|   NY|       7900|      26|\n",
      "|Marketing|   NY|       9100|      50|\n",
      "|Marketing|   CA|       8000|      25|\n",
      "+---------+-----+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"dept\",\"state\").min(\"salary\",\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agg\n",
    "* In case of applying multiple aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-------+\n",
      "|     dept|Min_sal|Avg_age|Max_age|\n",
      "+---------+-------+-------+-------+\n",
      "|    Sales|   8100|   40.0|     56|\n",
      "|  Finance|   7900|  35.75|     53|\n",
      "|Marketing|   8000|   37.5|     50|\n",
      "+---------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"dept\").agg(min(\"salary\").alias(\"Min_sal\"), \\\n",
    "                       avg(\"age\").alias(\"Avg_age\"),\\\n",
    "                      max(\"age\").alias(\"Max_age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where with aggregate groupBY() clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-------+\n",
      "|     dept|Min_sal|Avg_age|Max_age|\n",
      "+---------+-------+-------+-------+\n",
      "|    Sales|   8600|   45.0|     56|\n",
      "|  Finance|   7900|   39.5|     53|\n",
      "|Marketing|   9100|   50.0|     50|\n",
      "+---------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.state==\"NY\").groupBy(\"dept\").agg(min(\"salary\").alias(\"Min_sal\"), \\\n",
    "                       avg(\"age\").alias(\"Avg_age\"),\\\n",
    "                      max(\"age\").alias(\"Max_age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-------+\n",
      "| dept|Min_sal|Avg_age|Max_age|\n",
      "+-----+-------+-------+-------+\n",
      "|Sales|   8100|   40.0|     56|\n",
      "+-----+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"dept\").agg(min(\"salary\").alias(\"Min_sal\"), \\\n",
    "                       avg(\"age\").alias(\"Avg_age\"),\\\n",
    "                      max(\"age\").alias(\"Max_age\")).where(col(\"Avg_age\") > 38).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|     dept|state|salary|\n",
      "+---------+-----+------+\n",
      "|    Sales|   NY|  9000|\n",
      "|    Sales|   NY|  8600|\n",
      "|    Sales|   CA|  8100|\n",
      "|  Finance|   CA|  9000|\n",
      "|  Finance|   CA|  9900|\n",
      "|  Finance|   NY|  8300|\n",
      "|  Finance|   NY|  7900|\n",
      "|Marketing|   CA|  8000|\n",
      "|Marketing|   NY|  9100|\n",
      "+---------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.select(\"dept\",\"state\",\"salary\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+\n",
      "|     dept|state|sum(salary)|\n",
      "+---------+-----+-----------+\n",
      "|    Sales|   NY|      17600|\n",
      "|    Sales|   CA|       8100|\n",
      "|  Finance|   CA|      18900|\n",
      "|  Finance|   NY|      16200|\n",
      "|Marketing|   NY|       9100|\n",
      "|Marketing|   CA|       8000|\n",
      "+---------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df1.groupBy(\"dept\",\"state\").sum(\"salary\").alias(\"Salary\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|17600|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pi=df1.groupBy(\"dept\").pivot(\"state\").sum(\"sum(salary)\")\n",
    "pi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpivot\n",
    "* we dont have unpivot in spark, for that we have to use stack whic is a part of stack_SQL\n",
    "#### Stack Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col0|col1|\n",
      "+----+----+\n",
      "|   1|   2|\n",
      "|   3|   4|\n",
      "|   5|   6|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select stack(3, 1,2,3,4,5,6)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we pass 3 so (1,2,3,4,5,6) was conveted to 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|17600|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pi.createOrReplaceTempView('tab')\n",
    "\n",
    "spark.sql(\"\"\"select * from tab\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+\n",
      "|     dept|     State|Salary|\n",
      "+---------+----------+------+\n",
      "|    Sales|California|  8100|\n",
      "|    Sales|   NewYork| 17600|\n",
      "|  Finance|California| 18900|\n",
      "|  Finance|   NewYork| 16200|\n",
      "|Marketing|California|  8000|\n",
      "|Marketing|   NewYork|  9100|\n",
      "+---------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select dept,stack(2,\"California\",CA,\"NewYork\",NY) as (State,Salary) from tab\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+\n",
      "|     dept|state|sum(salary)|\n",
      "+---------+-----+-----------+\n",
      "|    Sales|   NY|      17600|\n",
      "|    Sales|   CA|       8100|\n",
      "|  Finance|   CA|      18900|\n",
      "|  Finance|   NY|      16200|\n",
      "|Marketing|   NY|       9100|\n",
      "|Marketing|   CA|       8000|\n",
      "+---------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## upper table is similar to\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------+\n",
      "|     dept|     State|Salary|\n",
      "+---------+----------+------+\n",
      "|    Sales|California|  8100|\n",
      "|    Sales|   NewYork| 17600|\n",
      "|  Finance|California| 18900|\n",
      "|  Finance|   NewYork| 16200|\n",
      "|Marketing|California|  8000|\n",
      "|Marketing|   NewYork|  9100|\n",
      "+---------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## we dont touch dept as we want it as it is\n",
    "pi.selectExpr(\"dept\",\"stack(2,'California',CA,'NewYork',NY) as (State,Salary)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window API\n",
    "* 3 types of window function\n",
    "* 1. Ranking\n",
    "* 2. Analytical\n",
    "* 3. Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking- used to provide a ranking to the result after the partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|Empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 26|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|  Kylie|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Sales\",\"NY\",9000,34),\n",
    "     (\"Alicia\",\"Sales\",\"NY\",8600,56),\n",
    "     (\"Robert\",\"Sales\",\"CA\",8100,30),\n",
    "     (\"John\",\"Sales\",\"AZ\",8600,31),\n",
    "     (\"Ross\",\"Sales\",\"AZ\",8100,33),\n",
    "     (\"Kathy\",\"Sales\",\"AZ\",1000,39),\n",
    "     (\"Lisa\",\"Finance\",\"CA\",9000,24),\n",
    "     (\"Deja\",\"Finance\",\"CA\",9900,40),\n",
    "     (\"Sugie\",\"Finance\",\"NY\",8300,26),\n",
    "     (\"Ram\",\"Finance\",\"NY\",7900,53),\n",
    "     (\"Satya\",\"Finance\",\"AZ\",8200,53),\n",
    "     (\"Kylie\",\"Marketing\",\"CA\",8000,25),\n",
    "     (\"Reid\",\"Marketing\",\"NY\",9100,50)]\n",
    "schema=(\"Empname\",\"dept\",\"state\",\"salary\",\"age\")\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec=Window.partitionBy(\"dept\").orderBy(col(\"salary\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+\n",
      "|     dept|salary|row_number_rank|\n",
      "+---------+------+---------------+\n",
      "|  Finance|  9900|              1|\n",
      "|  Finance|  9000|              2|\n",
      "|  Finance|  8300|              3|\n",
      "|  Finance|  8200|              4|\n",
      "|  Finance|  7900|              5|\n",
      "|Marketing|  9100|              1|\n",
      "|Marketing|  8000|              2|\n",
      "|    Sales|  9000|              1|\n",
      "|    Sales|  8600|              2|\n",
      "|    Sales|  8600|              3|\n",
      "|    Sales|  8100|              4|\n",
      "|    Sales|  8100|              5|\n",
      "|    Sales|  1000|              6|\n",
      "+---------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here note that \n",
    "* Sales|  8600|              2|\n",
    "* Sales|  8600|              3| ---> are same but still we get number 2 and , this is beacuse of row number, tht's why we use Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+\n",
      "|     dept|salary|row_number_rank|Rank|\n",
      "+---------+------+---------------+----+\n",
      "|  Finance|  9900|              1|   1|\n",
      "|  Finance|  9000|              2|   2|\n",
      "|  Finance|  8300|              3|   3|\n",
      "|  Finance|  8200|              4|   4|\n",
      "|  Finance|  7900|              5|   5|\n",
      "|Marketing|  9100|              1|   1|\n",
      "|Marketing|  8000|              2|   2|\n",
      "|    Sales|  9000|              1|   1|\n",
      "|    Sales|  8600|              2|   2|\n",
      "|    Sales|  8600|              3|   2|\n",
      "|    Sales|  8100|              4|   4|\n",
      "|    Sales|  8100|              5|   4|\n",
      "|    Sales|  1000|              6|   6|\n",
      "+---------+------+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note in here--\n",
    "* dept|salary|row_number_rank|Rank|\n",
    "* Sales|  8100|              5|   4|\n",
    "* Sales|  1000|              6|   6|\n",
    "* Here Rank from 4 goes to 6 coz it has 2 values of 4 so from 4 it goes directly to 6\n",
    "* Thats why we use DEnse Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+----------+\n",
      "|     dept|salary|row_number_rank|Rank|Dense_rank|\n",
      "+---------+------+---------------+----+----------+\n",
      "|  Finance|  9900|              1|   1|         1|\n",
      "|  Finance|  9000|              2|   2|         2|\n",
      "|  Finance|  8300|              3|   3|         3|\n",
      "|  Finance|  8200|              4|   4|         4|\n",
      "|  Finance|  7900|              5|   5|         5|\n",
      "|Marketing|  9100|              1|   1|         1|\n",
      "|Marketing|  8000|              2|   2|         2|\n",
      "|    Sales|  9000|              1|   1|         1|\n",
      "|    Sales|  8600|              2|   2|         2|\n",
      "|    Sales|  8600|              3|   2|         2|\n",
      "|    Sales|  8100|              4|   4|         3|\n",
      "|    Sales|  8100|              5|   4|         3|\n",
      "|    Sales|  1000|              6|   6|         4|\n",
      "+---------+------+---------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)) \\\n",
    ".withColumn(\"Dense_rank\",dense_rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+----------+------------+\n",
      "|     dept|salary|row_number_rank|Rank|Dense_rank|Percent_rank|\n",
      "+---------+------+---------------+----+----------+------------+\n",
      "|  Finance|  9900|              1|   1|         1|         0.0|\n",
      "|  Finance|  9000|              2|   2|         2|        0.25|\n",
      "|  Finance|  8300|              3|   3|         3|         0.5|\n",
      "|  Finance|  8200|              4|   4|         4|        0.75|\n",
      "|  Finance|  7900|              5|   5|         5|         1.0|\n",
      "|Marketing|  9100|              1|   1|         1|         0.0|\n",
      "|Marketing|  8000|              2|   2|         2|         1.0|\n",
      "|    Sales|  9000|              1|   1|         1|         0.0|\n",
      "|    Sales|  8600|              2|   2|         2|         0.2|\n",
      "|    Sales|  8600|              3|   2|         2|         0.2|\n",
      "|    Sales|  8100|              4|   4|         3|         0.6|\n",
      "|    Sales|  8100|              5|   4|         3|         0.6|\n",
      "|    Sales|  1000|              6|   6|         4|         1.0|\n",
      "+---------+------+---------------+----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)) \\\n",
    ".withColumn(\"Dense_rank\",dense_rank().over(spec)) \\\n",
    ".withColumn(\"Percent_rank\",percent_rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*      Sales|  9000|              1|   1|         1|         0.0|\n",
    "* |    Sales|  8600|              2|   2|         2|         0.2|\n",
    "* |    Sales|  8600|              3|   2|         2|         0.2|\n",
    "* |    Sales|  8100|              4|   4|         3|         0.6|\n",
    "* |    Sales|  8100|              5|   4|         3|         0.6|\n",
    "* |    Sales|  1000|              6|   6|         4|         1.0|\n",
    "\n",
    "* In here 1 is zero, now at 2--it is 2/5=.2 at num 3 \n",
    "* as well since 8600 is same for 2 and 3 row num, at num 4--3/5=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ntile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "|     dept|salary|row_number_rank|Rank|Dense_rank|Percent_rank|Ntile|\n",
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "|  Finance|  9900|              1|   1|         1|         0.0|    1|\n",
      "|  Finance|  9000|              2|   2|         2|        0.25|    2|\n",
      "|  Finance|  8300|              3|   3|         3|         0.5|    3|\n",
      "|  Finance|  8200|              4|   4|         4|        0.75|    4|\n",
      "|  Finance|  7900|              5|   5|         5|         1.0|    5|\n",
      "|Marketing|  9100|              1|   1|         1|         0.0|    1|\n",
      "|Marketing|  8000|              2|   2|         2|         1.0|    2|\n",
      "|    Sales|  9000|              1|   1|         1|         0.0|    1|\n",
      "|    Sales|  8600|              2|   2|         2|         0.2|    2|\n",
      "|    Sales|  8600|              3|   2|         2|         0.2|    3|\n",
      "|    Sales|  8100|              4|   4|         3|         0.6|    4|\n",
      "|    Sales|  8100|              5|   4|         3|         0.6|    5|\n",
      "|    Sales|  1000|              6|   6|         4|         1.0|    6|\n",
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)) \\\n",
    ".withColumn(\"Dense_rank\",dense_rank().over(spec)) \\\n",
    ".withColumn(\"Percent_rank\",percent_rank().over(spec)) \\\n",
    ".withColumn(\"Ntile\",ntile(6).over(spec)).show()\n",
    "## we pass 6 coz we know max variable i.e sales have 6 numbers-- so we pass 6 in NTILE(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we pass n=3 then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "|     dept|salary|row_number_rank|Rank|Dense_rank|Percent_rank|Ntile|\n",
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "|  Finance|  9900|              1|   1|         1|         0.0|    1|\n",
      "|  Finance|  9000|              2|   2|         2|        0.25|    1|\n",
      "|  Finance|  8300|              3|   3|         3|         0.5|    2|\n",
      "|  Finance|  8200|              4|   4|         4|        0.75|    2|\n",
      "|  Finance|  7900|              5|   5|         5|         1.0|    3|\n",
      "|Marketing|  9100|              1|   1|         1|         0.0|    1|\n",
      "|Marketing|  8000|              2|   2|         2|         1.0|    2|\n",
      "|    Sales|  9000|              1|   1|         1|         0.0|    1|\n",
      "|    Sales|  8600|              2|   2|         2|         0.2|    1|\n",
      "|    Sales|  8600|              3|   2|         2|         0.2|    2|\n",
      "|    Sales|  8100|              4|   4|         3|         0.6|    2|\n",
      "|    Sales|  8100|              5|   4|         3|         0.6|    3|\n",
      "|    Sales|  1000|              6|   6|         4|         1.0|    3|\n",
      "+---------+------+---------------+----+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)) \\\n",
    ".withColumn(\"Dense_rank\",dense_rank().over(spec)) \\\n",
    ".withColumn(\"Percent_rank\",percent_rank().over(spec)) \\\n",
    ".withColumn(\"Ntile\",ntile(3).over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+----+----------+------------+-----+-------------------+\n",
      "|     dept|salary|row_number_rank|Rank|Dense_rank|Percent_rank|Ntile|          Cumu_dist|\n",
      "+---------+------+---------------+----+----------+------------+-----+-------------------+\n",
      "|  Finance|  9900|              1|   1|         1|         0.0|    1|                0.2|\n",
      "|  Finance|  9000|              2|   2|         2|        0.25|    1|                0.4|\n",
      "|  Finance|  8300|              3|   3|         3|         0.5|    2|                0.6|\n",
      "|  Finance|  8200|              4|   4|         4|        0.75|    2|                0.8|\n",
      "|  Finance|  7900|              5|   5|         5|         1.0|    3|                1.0|\n",
      "|Marketing|  9100|              1|   1|         1|         0.0|    1|                0.5|\n",
      "|Marketing|  8000|              2|   2|         2|         1.0|    2|                1.0|\n",
      "|    Sales|  9000|              1|   1|         1|         0.0|    1|0.16666666666666666|\n",
      "|    Sales|  8600|              2|   2|         2|         0.2|    1|                0.5|\n",
      "|    Sales|  8600|              3|   2|         2|         0.2|    2|                0.5|\n",
      "|    Sales|  8100|              4|   4|         3|         0.6|    2| 0.8333333333333334|\n",
      "|    Sales|  8100|              5|   4|         3|         0.6|    3| 0.8333333333333334|\n",
      "|    Sales|  1000|              6|   6|         4|         1.0|    3|                1.0|\n",
      "+---------+------+---------------+----+----------+------------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"row_number_rank\",row_number().over(spec)) \\\n",
    ".withColumn(\"Rank\",rank().over(spec)) \\\n",
    ".withColumn(\"Dense_rank\",dense_rank().over(spec)) \\\n",
    ".withColumn(\"Percent_rank\",percent_rank().over(spec)) \\\n",
    ".withColumn(\"Ntile\",ntile(3).over(spec)) \\\n",
    ".withColumn(\"Cumu_dist\",cume_dist().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.8333333333333334\n",
      "----------------------------------------------------------------------------------------------------\n",
      "We get 0.5 because we do 3/5 coz 9000 is 1 nd 86000 ciunt to 2 and 3 so its 3/6 i.e 0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Similarly we get 5/6-0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(1/6)\n",
    "print(\"-\"*100)\n",
    "print(5/6)\n",
    "print(\"-\"*100)\n",
    "print(\"We get 0.5 because we do 3/5 coz 9000 is 1 nd 86000 ciunt to 2 and 3 so its 3/6 i.e {}\".format(3/6))\n",
    "print(\"-\"*100)\n",
    "print(\"Similarly we get 5/6-{}\".format(5/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1)-Lag-take 3 arguments(\"col_name\",lag_value,\"value when lag is not there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec=Window.partitionBy(\"dept\").orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|lag_column|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|        -1|\n",
      "|  Finance|  8300|      7900|\n",
      "|  Finance|  9000|      8300|\n",
      "|  Finance|  9900|      9000|\n",
      "|Marketing|  8000|        -1|\n",
      "|Marketing|  9100|      8000|\n",
      "|    Sales|  8100|        -1|\n",
      "|    Sales|  8600|      8100|\n",
      "|    Sales|  9000|      8600|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"lag_column\",lag(\"salary\",1,-1).over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check above\n",
    "* where there is no lag value its replaced by -1, and lag followed by 1 row each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+-----------+\n",
      "|     dept|salary|lag_column|lead_column|\n",
      "+---------+------+----------+-----------+\n",
      "|  Finance|  7900|        -1|       8300|\n",
      "|  Finance|  8300|      7900|       9000|\n",
      "|  Finance|  9000|      8300|       9900|\n",
      "|  Finance|  9900|      9000|         -1|\n",
      "|Marketing|  8000|        -1|       9100|\n",
      "|Marketing|  9100|      8000|         -1|\n",
      "|    Sales|  8100|        -1|       8600|\n",
      "|    Sales|  8600|      8100|       9000|\n",
      "|    Sales|  9000|      8600|         -1|\n",
      "+---------+------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"lag_column\",lag(\"salary\",1,-1).over(spec)) \\\n",
    ".withColumn(\"lead_column\",lead(\"salary\",1,-1).over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q- Print sum of salary according to each department ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+------+---+\n",
      "|Empname| dept|state|salary|age|\n",
      "+-------+-----+-----+------+---+\n",
      "|  James|Sales|   NY|  9000| 34|\n",
      "| Alicia|Sales|   NY|  8600| 56|\n",
      "| Robert|Sales|   CA|  8100| 30|\n",
      "+-------+-----+-----+------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Sales\",\"NY\",9000,34),\n",
    "     (\"Alicia\",\"Sales\",\"NY\",8600,56),\n",
    "     (\"Robert\",\"Sales\",\"CA\",8100,30),\n",
    "     (\"John\",\"Sales\",\"AZ\",8600,31),\n",
    "     (\"Ross\",\"Sales\",\"AZ\",8100,33),\n",
    "     (\"Kathy\",\"Sales\",\"AZ\",1000,39),\n",
    "     (\"Lisa\",\"Finance\",\"CA\",9000,24),\n",
    "     (\"Deja\",\"Finance\",\"CA\",9900,40),\n",
    "     (\"Sugie\",\"Finance\",\"NY\",8300,26),\n",
    "     (\"Ram\",\"Finance\",\"NY\",7900,53),\n",
    "     (\"Satya\",\"Finance\",\"AZ\",8200,53),\n",
    "     (\"Kylie\",\"Marketing\",\"CA\",8000,25),\n",
    "     (\"Reid\",\"Marketing\",\"NY\",9100,50)]\n",
    "schema=(\"Empname\",\"dept\",\"state\",\"salary\",\"age\")\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Sum_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  9000|     43300|\n",
      "|  Finance|  9900|     43300|\n",
      "|  Finance|  8300|     43300|\n",
      "|  Finance|  7900|     43300|\n",
      "|  Finance|  8200|     43300|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|     17100|\n",
      "|    Sales|  9000|     43400|\n",
      "|    Sales|  8600|     43400|\n",
      "|    Sales|  8100|     43400|\n",
      "|    Sales|  8600|     43400|\n",
      "|    Sales|  8100|     43400|\n",
      "|    Sales|  1000|     43400|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec=Window.partitionBy(\"dept\")\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Sum_salary\",sum(\"Salary\").over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* @- find out max salary from each dept using window funcctuon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  9900|      9900|\n",
      "|  Finance|  9000|      9900|\n",
      "|  Finance|  8300|      9900|\n",
      "|  Finance|  8200|      9900|\n",
      "|  Finance|  7900|      9900|\n",
      "|Marketing|  9100|      9100|\n",
      "|Marketing|  8000|      9100|\n",
      "|    Sales|  9000|      9000|\n",
      "|    Sales|  8600|      9000|\n",
      "|    Sales|  8600|      9000|\n",
      "|    Sales|  8100|      9000|\n",
      "|    Sales|  8100|      9000|\n",
      "|    Sales|  1000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec=Window.partitionBy(\"dept\").orderBy(col(\"Salary\").desc())\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",first(\"Salary\").over(spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range_between() and row_between()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec=Window.partitionBy(\"dept\").orderBy(df.salary). \\\n",
    "rowsBetween(Window.currentRow,Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     43300|\n",
      "|  Finance|  8200|     35400|\n",
      "|  Finance|  8300|     27200|\n",
      "|  Finance|  9000|     18900|\n",
      "|  Finance|  9900|      9900|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|      9100|\n",
      "|    Sales|  1000|     43400|\n",
      "|    Sales|  8100|     42400|\n",
      "|    Sales|  8100|     34300|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  8600|     17600|\n",
      "|    Sales|  9000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In finanace 9900+9000= 18900\n",
      "----------------------------------------------------------------------------------------------------\n",
      "In finanace 9900+9000+8300 = 27200\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Here\n",
    "print(\"In finanace 9900+9000= {}\".format(9900+9000))\n",
    "print(\"-\"*100)\n",
    "print(\"In finanace 9900+9000+8300 = {}\".format(9900+9000+8300))\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## range Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     43300|\n",
      "|  Finance|  8200|     35400|\n",
      "|  Finance|  8300|     27200|\n",
      "|  Finance|  9000|     18900|\n",
      "|  Finance|  9900|      9900|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|      9100|\n",
      "|    Sales|  1000|     43400|\n",
      "|    Sales|  8100|     42400|\n",
      "|    Sales|  8100|     42400|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  9000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec1=Window.partitionBy(\"dept\").orderBy(df.salary).rangeBetween(Window.currentRow,Window.unboundedFollowing)\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using (indow.unboundedPreceding),indow.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     43300|\n",
      "|  Finance|  8200|     43300|\n",
      "|  Finance|  8300|     43300|\n",
      "|  Finance|  9000|     43300|\n",
      "|  Finance|  9900|     43300|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|     17100|\n",
      "|    Sales|  1000|     43400|\n",
      "|    Sales|  8100|     43400|\n",
      "|    Sales|  8100|     43400|\n",
      "|    Sales|  8600|     43400|\n",
      "|    Sales|  8600|     43400|\n",
      "|    Sales|  9000|     43400|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec1=Window.partitionBy(\"dept\").orderBy(df.salary).rangeBetween(Window.unboundedPreceding,Window.unboundedFollowing)\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between rowBetween and rangebetween"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rangeBetween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     24400|\n",
      "|  Finance|  8200|     16500|\n",
      "|  Finance|  8300|      8300|\n",
      "|  Finance|  9000|      9000|\n",
      "|  Finance|  9900|      9900|\n",
      "|Marketing|  8000|      8000|\n",
      "|Marketing|  9100|      9100|\n",
      "|    Sales|  1000|      1000|\n",
      "|    Sales|  8100|     33400|\n",
      "|    Sales|  8100|     33400|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  9000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec1=Window.partitionBy(\"dept\").orderBy(df.salary).rangeBetween(Window.currentRow,500)\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SInce we define the boundry to 7900+500=8400, so its qualfiled till 8300 boundry to do the sum 24400\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Similarly 8200+500=8700, so its qualfiled till 8300 boundry to do the sum-16500\n"
     ]
    }
   ],
   "source": [
    "print(\" SInce we define the boundry to 7900+500=8400, so its qualfiled till 8300 boundry to do the sum {}\".format(7900+8200+8300))\n",
    "print(\"-\"*100)\n",
    "print(\"Similarly 8200+500=8700, so its qualfiled till 8300 boundry to do the sum-{}\".format(8200+8300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rowsbetween()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     43300|\n",
      "|  Finance|  8200|     35400|\n",
      "|  Finance|  8300|     27200|\n",
      "|  Finance|  9000|     18900|\n",
      "|  Finance|  9900|      9900|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|      9100|\n",
      "|    Sales|  1000|     43400|\n",
      "|    Sales|  8100|     42400|\n",
      "|    Sales|  8100|     34300|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  8600|     17600|\n",
      "|    Sales|  9000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec1=Window.partitionBy(\"dept\").orderBy(df.salary).rowsBetween(Window.currentRow,500)\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nothing happended it just simply dod the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----------+\n",
      "|     dept|salary|Max_salary|\n",
      "+---------+------+----------+\n",
      "|  Finance|  7900|     24400|\n",
      "|  Finance|  8200|     25500|\n",
      "|  Finance|  8300|     27200|\n",
      "|  Finance|  9000|     18900|\n",
      "|  Finance|  9900|      9900|\n",
      "|Marketing|  8000|     17100|\n",
      "|Marketing|  9100|      9100|\n",
      "|    Sales|  1000|     17200|\n",
      "|    Sales|  8100|     24800|\n",
      "|    Sales|  8100|     25300|\n",
      "|    Sales|  8600|     26200|\n",
      "|    Sales|  8600|     17600|\n",
      "|    Sales|  9000|      9000|\n",
      "+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spec1=Window.partitionBy(\"dept\").orderBy(df.salary).rowsBetween(Window.currentRow,2)\n",
    "df.select(\"dept\",\"salary\").withColumn(\"Max_salary\",sum(\"Salary\").over(spec1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * In here its simply adding the do preceding rows together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= spark.range(100)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  9|\n",
      "| 10|\n",
      "| 15|\n",
      "| 19|\n",
      "| 25|\n",
      "| 33|\n",
      "| 46|\n",
      "| 51|\n",
      "| 52|\n",
      "| 57|\n",
      "| 60|\n",
      "| 78|\n",
      "| 80|\n",
      "| 86|\n",
      "| 87|\n",
      "| 89|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(fraction=0.2).show() ## Showing 20% of data as we pass frction=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 10|\n",
      "| 12|\n",
      "| 17|\n",
      "| 18|\n",
      "| 23|\n",
      "| 23|\n",
      "| 35|\n",
      "| 37|\n",
      "| 39|\n",
      "| 42|\n",
      "| 59|\n",
      "| 74|\n",
      "| 77|\n",
      "| 80|\n",
      "| 84|\n",
      "| 96|\n",
      "| 98|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(fraction=0.2,withReplacement=True).show() ## withReplacement=False means every elemt is unique,if taken out its not placed back\n",
    "                                                    #withReplacement True we are allowing dublicate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  6|\n",
      "|  8|\n",
      "| 17|\n",
      "| 30|\n",
      "| 31|\n",
      "| 42|\n",
      "| 45|\n",
      "| 52|\n",
      "| 60|\n",
      "| 61|\n",
      "| 63|\n",
      "| 68|\n",
      "| 69|\n",
      "| 73|\n",
      "| 75|\n",
      "| 75|\n",
      "| 79|\n",
      "| 83|\n",
      "| 86|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Using Seed--it gives same data everytme\n",
    "df.sample(fraction=0.2,withReplacement=True,seed=10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Key|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  0|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.range(100).select((col(\"id\") % 3).alias(\"Key\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Key|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want 10% of zero, 40% of one then we use SampleBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Key|\n",
      "+---+\n",
      "|  1|\n",
      "|  0|\n",
      "|  1|\n",
      "|  1|\n",
      "|  0|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  0|\n",
      "|  1|\n",
      "|  0|\n",
      "|  1|\n",
      "|  1|\n",
      "|  0|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample=df.sampleBy(\"Key\",fractions={0:0.1,1:0.4},seed=20)\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Key|count|\n",
      "+---+-----+\n",
      "|  0|    5|\n",
      "|  1|   14|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample.groupBy(\"Key\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other aggregate fumctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|Empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  null| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   John|    Sales|   AZ|  8600| 31|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 26|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|\n",
      "|  Kylie|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(\"James\",\"Sales\",\"NY\",None,34),\n",
    "     (\"Alicia\",\"Sales\",\"NY\",8600,56),\n",
    "     (\"Robert\",\"Sales\",\"CA\",8100,30),\n",
    "     (\"John\",\"Sales\",\"AZ\",8600,31),\n",
    "     (\"Ross\",\"Sales\",\"AZ\",8100,33),\n",
    "     (\"Kathy\",\"Sales\",\"AZ\",1000,39),\n",
    "     (\"Lisa\",\"Finance\",\"CA\",9000,24),\n",
    "     (\"Deja\",\"Finance\",\"CA\",9900,40),\n",
    "     (\"Sugie\",\"Finance\",\"NY\",8300,26),\n",
    "     (\"Ram\",\"Finance\",\"NY\",7900,53),\n",
    "     (\"Satya\",\"Finance\",\"AZ\",8200,53),\n",
    "     (\"Kylie\",\"Marketing\",\"CA\",8000,25),\n",
    "     (\"Reid\",\"Marketing\",\"NY\",9100,50)]\n",
    "schema=(\"Empname\",\"dept\",\"state\",\"salary\",\"age\")\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|         null|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(first(df.salary)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|         8600|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## If we dont want nulll then\n",
    "df.select(first(df.salary,ignorenulls=True)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|        9100|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(last(df.salary)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|greatest(age, salary)|\n",
      "+---------------------+\n",
      "|                   34|\n",
      "|                 8600|\n",
      "|                 8100|\n",
      "|                 8600|\n",
      "|                 8100|\n",
      "|                 1000|\n",
      "|                 9000|\n",
      "|                 9900|\n",
      "|                 8300|\n",
      "|                 7900|\n",
      "|                 8200|\n",
      "|                 8000|\n",
      "|                 9100|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(greatest(df.age,df.salary)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|least(age, salary)|\n",
      "+------------------+\n",
      "|                34|\n",
      "|                56|\n",
      "|                30|\n",
      "|                31|\n",
      "|                33|\n",
      "|                39|\n",
      "|                24|\n",
      "|                40|\n",
      "|                26|\n",
      "|                53|\n",
      "|                53|\n",
      "|                25|\n",
      "|                50|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(least(df.age,df.salary)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect_list--> allow duplicate values as well eg-53 in below example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+\n",
      "|collect_list(age)                                   |\n",
      "+----------------------------------------------------+\n",
      "|[34, 56, 30, 31, 33, 39, 24, 40, 26, 53, 53, 25, 50]|\n",
      "+----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_list(df.age)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect_Set--> don't allow duplicate values eg-53 only come one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|collect_set(age)                                |\n",
      "+------------------------------------------------+\n",
      "|[33, 30, 34, 31, 56, 53, 50, 24, 39, 25, 40, 26]|\n",
      "+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_set(df.age)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Functions\n",
    "* 1- Concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Concat_col|\n",
      "+----------+\n",
      "|      null|\n",
      "|   8600|56|\n",
      "|   8100|30|\n",
      "|   8600|31|\n",
      "|   8100|33|\n",
      "|   1000|39|\n",
      "|   9000|24|\n",
      "|   9900|40|\n",
      "|   8300|26|\n",
      "|   7900|53|\n",
      "|   8200|53|\n",
      "|   8000|25|\n",
      "|   9100|50|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(concat(col(\"salary\"),lit(\"|\"),col(\"age\")).alias(\"Concat_col\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If age <30 \"KID\", age >30 and <45 \"Mid_age\" more than 45 OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+------+\n",
      "|Empname|     dept|state|salary|age|Status|\n",
      "+-------+---------+-----+------+---+------+\n",
      "|  James|    Sales|   NY|  null| 34|Adults|\n",
      "| Alicia|    Sales|   NY|  8600| 56|   Men|\n",
      "| Robert|    Sales|   CA|  8100| 30|   Men|\n",
      "|   John|    Sales|   AZ|  8600| 31|Adults|\n",
      "|   Ross|    Sales|   AZ|  8100| 33|Adults|\n",
      "|  Kathy|    Sales|   AZ|  1000| 39|Adults|\n",
      "|   Lisa|  Finance|   CA|  9000| 24|   KID|\n",
      "|   Deja|  Finance|   CA|  9900| 40|Adults|\n",
      "|  Sugie|  Finance|   NY|  8300| 26|   KID|\n",
      "|    Ram|  Finance|   NY|  7900| 53|   Men|\n",
      "|  Satya|  Finance|   AZ|  8200| 53|   Men|\n",
      "|  Kylie|Marketing|   CA|  8000| 25|   KID|\n",
      "|   Reid|Marketing|   NY|  9100| 50|   Men|\n",
      "+-------+---------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Status\",when(col(\"age\")<30,\"KID\").\\\n",
    "               when((df.age>30) & (df.age <45),\"Adults\").\\\n",
    "              otherwise(\"Men\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parttions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=spark.range(10)\n",
    "df1.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doing re_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.repartition(5)\n",
    "df1.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the ID'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| ID|SPARK_PARTITION_ID()|\n",
      "+---+--------------------+\n",
      "|  6|                   0|\n",
      "|  7|                   0|\n",
      "|  0|                   1|\n",
      "|  3|                   1|\n",
      "|  8|                   1|\n",
      "|  1|                   2|\n",
      "|  2|                   2|\n",
      "|  9|                   2|\n",
      "|  4|                   3|\n",
      "|  5|                   4|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(\"ID\",spark_partition_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here id's (6-7) belongs to ID ZERO, Id's (0,3,8) belongs to ID ONE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.load('orders/part-00000',format=\"csv\",schema='order_id int,order_date timestamp,order_customer_id int, \\\n",
    "                   order_status string')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|               s|\n",
      "+----------------+\n",
      "|[oneAtwoBthreeC]|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dd = spark.createDataFrame([('oneAtwoBthreeC',)], ['s',])\n",
    "dd.select(split(dd.s, '[ABC]', 1).alias('s')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+--------------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|                Year|\n",
      "+--------+-------------------+-----------------+---------------+--------------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|[2013, 07, 25 00:...|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|[2013, 07, 25 00:...|\n",
      "+--------+-------------------+-----------------+---------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",split(df.order_date,\"-\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|Year|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",split(df.order_date,\"-\")[0]).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|           col|\n",
      "+--------------+\n",
      "|ab12cd23fe27kl|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(\"ab12cd23fe27kl\",)],[\"col\",])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|split(col, [0-9]+, -1)|\n",
      "+----------------------+\n",
      "|      [ab, cd, fe, kl]|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(df.col,'[0-9]+')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|   order_status|staus_length|\n",
      "+---------------+------------+\n",
      "|         CLOSED|           6|\n",
      "|PENDING_PAYMENT|          15|\n",
      "|       COMPLETE|           8|\n",
      "|         CLOSED|           6|\n",
      "|       COMPLETE|           8|\n",
      "+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"order_status\"),length(col(\"order_status\")).alias(\"staus_length\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|     lower_stat|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         closed|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|pending_payment|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.withColumn(\"lower_stat\",lower(col(\"order_status\")))\n",
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|     lower_stat|initcap(order_status)|\n",
      "+---------------+---------------------+\n",
      "|         closed|               Closed|\n",
      "|pending_payment|      Pending_payment|\n",
      "|       complete|             Complete|\n",
      "+---------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(col(\"lower_stat\"),initcap(col(\"order_status\"))).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|col1                       |\n",
      "+---------------------------+\n",
      "|          spark            |\n",
      "|          developer        |\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(\"          spark        \",),(\"          developer        \",)],schema=[\"col1\"])\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                col1|trimmed_val|\n",
      "+--------------------+-----------+\n",
      "|          spark  ...|      spark|\n",
      "|          develop...|  developer|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"trimmed_val\",trim(col(\"col1\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ltrim-- Trim Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----------------+\n",
      "|col1                       |trim_left        |\n",
      "+---------------------------+-----------------+\n",
      "|          spark            |spark            |\n",
      "|          developer        |developer        |\n",
      "+---------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"trim_left\",ltrim(col(\"col1\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rtrim--- Trim Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------+\n",
      "|col1                       |trim_right         |\n",
      "+---------------------------+-------------------+\n",
      "|          spark            |          spark    |\n",
      "|          developer        |          developer|\n",
      "+---------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"trim_right\",rtrim(col(\"col1\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lpad-- Padding left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|order_id|padding_left|\n",
      "+--------+------------+\n",
      "|       1|       @@@@1|\n",
      "|       2|       @@@@2|\n",
      "|       3|       @@@@3|\n",
      "|       4|       @@@@4|\n",
      "|       5|       @@@@5|\n",
      "+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"order_id\"),lpad(df.order_id,5,\"@\").alias(\"padding_left\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rpad-- Padding right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|order_id|padding_right|\n",
      "+--------+-------------+\n",
      "|       1|        1####|\n",
      "|       2|        2####|\n",
      "|       3|        3####|\n",
      "|       4|        4####|\n",
      "|       5|        5####|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"order_id\"),rpad(df.order_id,5,\"#\").alias(\"padding_right\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|   order_status| Reverse_string|\n",
      "+---------------+---------------+\n",
      "|         CLOSED|         DESOLC|\n",
      "|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|       COMPLETE|       ETELPMOC|\n",
      "|         CLOSED|         DESOLC|\n",
      "|       COMPLETE|       ETELPMOC|\n",
      "+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"order_status\"),reverse(df.order_status).alias(\"Reverse_string\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|   order_status| repeat_order_status|\n",
      "+---------------+--------------------+\n",
      "|         CLOSED|        CLOSEDCLOSED|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENTPE...|\n",
      "|       COMPLETE|    COMPLETECOMPLETE|\n",
      "|         CLOSED|        CLOSEDCLOSED|\n",
      "|       COMPLETE|    COMPLETECOMPLETE|\n",
      "+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"order_status\"),repeat(df.order_status,2).alias(\"repeat_order_status\")).show(5) # repating 2 times as we passed 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|         concated|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         1,CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2,PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       3,COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         4,CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       5,COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"concated\",concat(col(\"order_id\"),lit(\",\"),df.order_status)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat_ws-- concate with separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|         concated|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         1#CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2#PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       3#COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         4#CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       5#COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"concated\",concat_ws(\"#\",col(\"order_id\"),df.order_status)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|Year|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",substring(df.order_date,1,4)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substring_index-- Works like scan in SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|Year|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",substring_index(df.order_date,\"-\",1)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|   Year|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013-07|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013-07|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013-07|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013-07|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013-07|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",substring_index(df.order_date,\"-\",2)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|Year|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|  07|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|  07|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|  07|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|  07|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|  07|\n",
      "+--------+-------------------+-----------------+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",substring(substring_index(df.order_date,\"-\",2),6,8)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instr--- Locate  position of first occurance of substring in given string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|PositionOfString|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|               2|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|               0|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|               0|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|               2|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|               0|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"PositionOfString\",instr(df.order_status,\"LO\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOcate(sunstringTofind, String,Position(from where we want to start findling the word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|PositionOfString|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|               5|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|              13|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|               6|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|               5|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|               6|\n",
      "+--------+-------------------+-----------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"PositionOfString\",locate(\"E\",df.order_status,3)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      col|\n",
      "+---------+\n",
      "|translate|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(\"translate\",)],(\"col\",))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|      col|translate|\n",
      "+---------+---------+\n",
      "|translate|  1a2s3ae|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"translate\",translate(df.col,\"rnlt\",\"123\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here\n",
    "* r is replaced by 1\n",
    "* n is replaced by 2\n",
    "* l is replaced by 3\n",
    "* t is replaced by blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay\n",
    "* replace SQL with CORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|        X|   Y|\n",
      "+---------+----+\n",
      "|SPARK_SQL|CORE|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.createDataFrame([(\"SPARK_SQL\",\"CORE\")],(\"X\",\"Y\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------------+\n",
      "|        X|   Y|Overlayed_colmn|\n",
      "+---------+----+---------------+\n",
      "|SPARK_SQL|CORE|     SPARK_CORE|\n",
      "+---------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Overlayed_colmn\",overlay(df.X,df.Y,7)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SPARK_HOME]",
   "language": "python",
   "name": "conda-env-SPARK_HOME-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
